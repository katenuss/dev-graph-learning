---
title: "Graph Learning Analyses"
author: "Kate Nussenbaum"
date: "1/6/26"
output: 
    html_document:
        df_print: 'paged'
        toc: true
        toc_float:
            collapsed: false
            smooth_scroll: true
        number_sections: false
        code_download: true
        self_contained: true
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, cache = TRUE)
knitr::opts_chunk$set(fig.path = "figures/results_figures/")
```

```{r libraries}
library(tidyverse)
library(afex)
library(sjPlot)
library(pander)
library(knitr)
library(xtable)
library(jsonlite)
library(glue)
library(igraph)

#functions
#determine plotting colors
plot_colors = c("#DD8D29", "#E2D200", "#46ACC8", "#E58601", "#B40F20")

#define plotting theme
graph_theme <- function () {
  theme(
    text=element_text(family="Arial"),
    line = element_blank(),
    title = element_text(size = 20),
    panel.border = element_rect(fill = "transparent", color="black"),
    panel.background  = element_blank(),
    plot.background = element_blank(), 
    legend.background = element_rect(fill="transparent", colour=NA),
    legend.key = element_rect(fill="transparent", colour=NA),
    legend.text = element_text(size = 16),
    axis.ticks = element_line(color="black"),
    axis.text = element_text(size = 14),
    axis.title = element_text(size = 18),
    strip.text = element_text(size=14)
  )
}

#avoid scientific notation
options(scipen = 100, digits = 4)
```

```{r directories}

# Read in data
data_dir = 'data/sub_data/'

```

# Tasks

Participants completed three tasks: 1.) Graph-learning, 2.) Graph-parsing, and 3.) Graph-reconstruction.

## Learning task
In the learning task, on each trial, participants saw a series of planets with overlaid gabor patches. Participants had to press one of two keys to indicate the 'direction of the wind' on the planet, as indicated by the gabor. Wind directions were determined randomly on every trial.

Unbeknownst to participants, the order of the planets was determined by a random walk along a modular graph. Each planet transitioned with 25% probability to one of 4 other planets. The graph structure created three 'communities' of planets, and two types of transitions: within-community transitions, and between-community transitions. Participants completed a total of 600 learning trials.


## Parsing task
After the learning task, participants completed a 'parsing' task, in which they once again saw a sequence of planets (following the same random walk) and had to press the space bar to indicate when they believed they had entered a different part of the galaxy.

Participants completed a total of 600 parsing trials.

## Graph reconstruction
At the end of the experiment, participants saw all the planets placed randomly on the screen. They were told to drag them around the screen to create a map based on how they thought 'the planets were spread out across the universe.' Participants could click on each planet to move them around the screen, pressing a final button to submit their map when they were happy with it.


```{r define functions}
#z-score
scale_this <- function(x){
  (x - mean(x, na.rm=TRUE)) / sd(x, na.rm=TRUE)
}


#print results from linear mixed-effects models
print_model_results <- function(model_name) {
  
  #get F and p values
  model_effects <- as.data.frame(nice(model_name, 
                      sig_symbols = rep("", 4))) %>%
  dplyr::select(Effect, df, `F`, p.value) 

  #get coefficients and standard error
  coefficients <- as.data.frame(coef(summary(model_name))) %>%
    dplyr::select(Estimate, `Std. Error`) %>%
    rownames_to_column("Effect") %>%
    mutate(Effect = gsub("[0-9]", "", Effect))   #remove numbers from effects

  #merge 
  model_results <- full_join(coefficients, model_effects, by = "Effect") %>%
    dplyr::select(Effect, Estimate, `Std. Error`, df, `F`, p.value) 
  
  #return
  return(model_results)
}

#print results from logistic mixed-effects models
print_log_model_results <- function(model_name) {
  
  #get F and p values
  model_effects <- as.data.frame(nice(model_name, 
                      sig_symbols = rep("", 4))) %>%
  dplyr::select(Effect, df, Chisq, p.value) 

  #get coefficients and standard error
  coefficients <- as.data.frame(coef(summary(model_name))) %>%
    dplyr::select(Estimate, `Std. Error`) %>%
    rownames_to_column("Effect") %>%
    mutate(Effect = gsub("[0-9]", "", Effect))   #remove numbers from effects

  #merge 
  model_results <- full_join(coefficients, model_effects, by = "Effect") %>%
    dplyr::select(Effect, Estimate, `Std. Error`, df, `Chisq`, p.value) 
  
  #return
  return(model_results)
}
```

```{r import data}
#read and compile all data
data_all <- list.files(path = data_dir,  
                       pattern = "graph_learning*", 
                       full.names = TRUE) %>% 
  lapply(read_csv) %>%
  bind_rows
```


```{r add demographic data}

#add sub ages
age_data <- read_csv(glue("data/participant_ages.csv")) %>%
    dplyr::select(subject_id = "Subject ID", age = Age)

#convert age to numeric
age_data$age <- as.numeric(age_data$age)

#join with data
data_all <- inner_join(data_all, age_data, by = "subject_id") 

#add age info
data_all <- data_all %>% mutate(age_group = case_when(age < 13 ~ "Children",
                                age > 12.99 & age < 18 ~ "Adolescents",
                                age > 17.99 ~ "Adults"))

data_all$age_group <- factor(data_all$age_group, levels = c("Children", "Adolescents", "Adults"))
```


```{r process learning data}
learning_data <- data_all %>%
  filter(block %in% c('learnblock1', 'learnblock2')) %>%
  dplyr::select(time_elapsed, subject_id, age, age_group, block, trial_index, stimulus, planet, community, rt, key_press, learning_correct_response) %>%
    group_by(subject_id, block) %>%
    mutate(prev_community = lag(community),
           within_block_trial = rank(trial_index),
           block_number = parse_number(as.character(block)),
           trial = within_block_trial + 300*(block_number-1),
           correct = ifelse(key_press == learning_correct_response, 1, 0)) %>%
    ungroup() %>%
  group_by(subject_id, block) %>%
    mutate(transition_type = ifelse(prev_community == community, "within", "between")) %>%
  ungroup()

#convert RT to numeric
learning_data$rt <- as.numeric(learning_data$rt)
```


```{r compute duration from start of last trial of block 1 to start of block 2}

duration_between_blocks <- learning_data %>%
  filter(trial == 300 | trial == 301) %>%
  group_by(subject_id) %>%
  mutate(prev_trial_start = lag(time_elapsed),
         time_between_blocks = time_elapsed - prev_trial_start) %>%
  filter(trial == 301) %>%
  select(subject_id, time_between_blocks)

```


# Format data for SR modeling
```{r format for SR modeling}
#format:

# subject id
# age
# block
# within_block_trial
# node (1 - 15)
# target_button 
# stim_id
# rt
# isValid (correct response, rt > 200 ms)
# exclude_sub

#select relevant columns
model_data <- learning_data %>%
  mutate(block_num = parse_number(block), community_num = parse_number(community), prev_community_num = parse_number(prev_community)) %>%
  dplyr::select(subject_id, age, block_num, within_block_trial, stim_id = planet, community_num, prev_community_num, transition_type, target_button = learning_correct_response, key_press, correct, rt) %>%
  mutate(isValid = ifelse(correct == 1 & rt > 200, 1, 0)) 

#identify edge (exterior) vs central (interior) planets
exterior_planets <- model_data %>%
  group_by(subject_id, stim_id, community_num, prev_community_num, transition_type) %>%
  summarize(N = n()) %>%
  filter(transition_type == "between") %>%
  mutate(node = case_when(community_num == 1 & prev_community_num == 3 ~ 1,
                          community_num == 1 & prev_community_num == 2 ~ 5,
                          community_num == 2 & prev_community_num == 1 ~ 6,
                          community_num == 2 & prev_community_num == 3 ~ 10,
                          community_num == 3 & prev_community_num == 1 ~ 15,
                          community_num == 3 & prev_community_num == 2 ~ 11),
         planet_type = "exterior") %>%
  ungroup() %>%
  dplyr::select(subject_id, stim_id, node, planet_type)


interior_planets_temp <- model_data %>%
  dplyr::select(subject_id, community_num, stim_id) %>%
  unique()

#join
interior_planets <- full_join(interior_planets_temp, exterior_planets, by = c("subject_id", "stim_id")) %>%
  mutate(planet_type = replace_na(planet_type, "interior")) %>%
  filter(planet_type == "interior") %>%
  group_by(subject_id, community_num) %>%
  mutate(node_temp = rank(stim_id),
         node = node_temp + ((community_num-1)*5) + 1) %>%
  ungroup() %>%
  dplyr::select(subject_id, stim_id, node, planet_type)

#create all planets dataframe
all_planets = rbind(interior_planets, exterior_planets)

#recode NA rts as 0
model_data <- model_data %>%
  mutate(rt = replace_na(rt, 0))

#put back into model data
model_data_node <- full_join(model_data, all_planets, by = c("subject_id", "stim_id")) %>%
  dplyr::select(subject_id, age, block_num, within_block_trial, node, target_button, stim_id, rt, isValid)
```


# Apply participant exclusions 
Participants were excluded from the learning task if they meet any of the following criteria:
- More than 20 browser interactions
- Less than 75% accuracy on learning trials (excluding missed trials)
- More than 20% (120) of learning trials missed 
- More than 20% (120 of learning trials fast (< 200 ms))
- More than 30 minutes (1800000 ms) from start of last trial of block 1 to first trial of block 2

```{r compute learning data exclusions}

#determine bad subjects based on browser interactions
bad_browser_subs <- data_all %>%
  filter(browser_interactions > 20) %>%
  dplyr::select(subject_id, age_group) %>%
  unique()

#determine exclusions
learning_data_summary <- learning_data %>%
  group_by(subject_id, age_group) %>%
  summarize(missed_trials = sum(key_press == "null"),
            inaccurate_trials = sum(correct == 0),
            accurate_trials = sum(correct == 1),
            mean_acc = accurate_trials/(accurate_trials + inaccurate_trials - missed_trials),
            mean_rt = mean(rt, na.rm = T),
            fast_rts = sum(rt < 200, na.rm = T),
            n_trials = n()) %>%
  mutate(exclude_missed = ifelse(missed_trials > 120, 1, 0),
         exclude_acc = ifelse(mean_acc < .75, 1, 0),
         exclude = sum(exclude_missed + exclude_acc)) 

#
bad_missed_subs <- learning_data_summary %>%
  filter(exclude_missed == 1)

bad_acc_subs <- learning_data_summary %>%
  filter(exclude_acc == 1)

bad_rt_subs <- learning_data_summary %>%
  filter(fast_rts > 120)

incomplete_subs <- learning_data_summary %>%
  filter(n_trials < 600)

long_break_subs <- duration_between_blocks %>%
  filter(time_between_blocks > 1800000)
```

```{r label bad participants in model data}

final_model_data <- model_data_node %>%
  mutate(bad_browser_sub = ifelse(subject_id %in% bad_browser_subs$subject_id, 1, 0),
         bad_missed_trials = ifelse(subject_id %in% bad_missed_subs$subject_id, 1, 0),
         bad_acc_trials = ifelse(subject_id %in% bad_acc_subs$subject_id, 1, 0),
         fast_rt_subs = ifelse(subject_id %in% bad_rt_subs$subject_id, 1, 0),
         incomplete_subs = ifelse(subject_id %in% incomplete_subs$subject_id, 1, 0),
         long_break_subs = ifelse(subject_id %in% long_break_subs$subject_id, 1, 0))

final_model_data <- final_model_data %>%
  mutate(exclude = ifelse(bad_browser_sub == 1 | bad_missed_trials == 1 | bad_acc_trials == 1 | fast_rt_subs == 1 | incomplete_subs == 1 | long_break_subs == 1, 1, 0)) %>%
  filter(exclude == 0)

#save csv
write_csv(final_model_data, "data/processed/model_data.csv")
```


```{r plot participant exclusions}

#browser interactions
browser_int_plot <- ggplot(data_all %>% 
                             dplyr::select(subject_id, age_group, browser_interactions) %>% unique(), aes(x = browser_interactions)) +
  geom_histogram(fill = plot_colors[3], color = 'black', bins = 100) +
  xlab("Browser Interactions") +
  ylab("Number of Participants") +
  geom_vline(xintercept = 20, linetype = 'dashed') +
  graph_theme()
browser_int_plot 

#missed learning trials
missed_trials_plot <- ggplot(learning_data_summary, aes(x = missed_trials)) +
  geom_histogram(fill = plot_colors[3], color = 'black', bins = 100) +
  xlab("Missed Learning Trials") +
  ylab("Number of Participants") +
  geom_vline(xintercept = 120, linetype = 'dashed') +
  graph_theme()
missed_trials_plot

#inaccuracy
learning_acc_plot <- ggplot(learning_data_summary, aes(x = mean_acc)) +
  geom_histogram(fill = plot_colors[3], color = 'black', bins = 100) +
  xlab("Learning Accuracy") +
  ylab("Number of Participants") +
  geom_vline(xintercept = .75, linetype = 'dashed') +
  graph_theme()
learning_acc_plot

#fast reaction times
fast_rt_plot <- ggplot(learning_data_summary, aes(x = fast_rts)) +
  geom_histogram(fill = plot_colors[3], color = 'black', bins = 100) +
  xlab("Fast RTs (< 150 ms)") +
  ylab("Number of Participants") +
  geom_vline(xintercept = 120, linetype = 'dashed') +
  graph_theme()
fast_rt_plot

#long break
long_break_plot <- ggplot(duration_between_blocks, aes(x = time_between_blocks)) +
  geom_histogram(fill = plot_colors[3], color = 'black', bins = 100) +
  xlab("Break Between Learning Blocks (> 30 minutes)") +
  ylab("Number of Participants") +
  geom_vline(xintercept = 1800000, linetype = 'dashed') +
  graph_theme()
long_break_plot
```

```{r apply learning exclusions}

#count excluded participants 
n_bad_browser <- bad_browser_subs %>%
  group_by(age_group, .drop = F) %>%
  summarize(exclude_browser = n())

#exclude from learning data summary
learning_summary2 <- learning_data_summary %>%
  filter(!subject_id %in% bad_browser_subs$subject_id)

#now count missed exclusions (after accounting for bad browser subs)
n_missed_trials <- learning_summary2 %>%
  filter(exclude_missed == 1) %>%
  group_by(age_group, .drop = F) %>%
  summarize(exclude_missed_trials = n())

bad_missed_subs <- learning_data_summary %>% 
  filter(exclude_missed == 1)

#exclude from learning data summary
learning_summary3 <- learning_summary2 %>%
  filter(!subject_id %in% bad_missed_subs$subject_id)

#now count accuracy exclusions
n_low_acc <- learning_summary3 %>%
  filter(exclude_acc == 1) %>%
  group_by(age_group, .drop = F) %>%
  summarize(exclude_acc = n())

bad_acc_subs <- learning_data_summary %>% 
  filter(exclude_acc == 1)

#exclude from learning data summary
learning_summary4 <- learning_summary3 %>%
  filter(!subject_id %in% bad_acc_subs$subject_id)

#now count RT exclusions
n_fast_rt <- learning_summary4 %>%
  filter(fast_rts > 120) %>%
  group_by(age_group, .drop = F) %>%
  summarize(exclude_fast_rts = n()) %>%
  mutate(exclude_fast_rts = replace_na(exclude_fast_rts, 0)) 

bad_rt_subs <- learning_data_summary %>%
  filter(fast_rts > 120)

#exclude from learning data summary
learning_summary5 <- learning_summary4 %>%
  filter(!subject_id %in% bad_rt_subs$subject_id) 

#now count break exclusions
n_long_break <- learning_summary5 %>%
  left_join(duration_between_blocks, by = c("subject_id")) %>%
  filter(time_between_blocks > 1800000) %>%
  group_by(age_group, .drop = F) %>%
  summarize(exclude_long_break = n()) 

bad_break_subs <- duration_between_blocks %>%
  filter(time_between_blocks > 1800000)

  
#make table of exclusions
exclusion_data <- full_join(n_bad_browser, n_missed_trials, by = "age_group") %>%
  left_join(., n_low_acc, by="age_group") %>%
  left_join(., n_fast_rt, by="age_group") %>%
  left_join(., n_long_break, by = "age_group") %>%
  rowwise() %>%
  mutate(total_excluded = exclude_browser + exclude_missed_trials + exclude_acc + exclude_fast_rts + exclude_long_break)
pander(exclusion_data)
  
#determine overall bad learning subs
good_learning_subs <- learning_data_summary %>%
  filter(exclude == 0) %>%
  filter(fast_rts < 120)

#filter based on browser interactions
filtered_learning_data <- learning_data %>%
  filter(!subject_id %in% bad_browser_subs$subject_id) %>%
  filter(subject_id %in% good_learning_subs$subject_id) %>%
  filter(!subject_id %in% incomplete_subs$subject_id) %>%
  filter(!subject_id %in% bad_break_subs$subject_id)

#determine number of included participants
included_participants <- filtered_learning_data %>%
  dplyr::select(subject_id, age_group) %>%
  unique() %>%
  group_by(age_group) %>%
  summarize(N = n())
pander(included_participants)
```


# Results

## Learning
For all learning analyses, we will examine only accurate trials in which participants responded in > 200 ms

### Response time distributions

```{r plot rt cutoff}
ggplot(filtered_learning_data %>% filter(correct == T), aes(x = rt)) +
    facet_wrap(~age_group) +
    geom_histogram(color = "black", fill = plot_colors[3], bins = 40) +
    xlab("Reaction Time (ms) on Correct Trials") +
    ylab("Count") +
    geom_vline(xintercept = 200, linetype = "dashed") +
    graph_theme()

```


### Response times by age, within block trial, block, planet lag, transition type
```{r planet lag data processing}
planet_encountered_data <- filtered_learning_data %>%
  group_by(subject_id) %>%
  group_by(planet) %>%
  mutate(planet_lag = within_block_trial - lag(within_block_trial, default = first(within_block_trial)) - 1) %>%
  ungroup() %>%
  dplyr::select(rt, transition_type, block, within_block_trial,trial, subject_id, age, planet, learning_correct_response, planet_lag, correct) %>%
  filter(planet_lag > 0) 

#sanity check - is within < between?
planet_encountered_means <- planet_encountered_data %>%
  group_by(transition_type) %>%
  summarize(mean_lag = mean(planet_lag),
            sd_lag = sd(planet_lag))

pander(planet_encountered_means)

#filter planet encountered data
planet_encountered_data <- planet_encountered_data %>%
  filter(planet_lag > 0) %>%
  filter(correct == T) %>% 
  filter(rt > 200) %>%
  drop_na()
```

```{r learning rt model}

#transform variables
planet_encountered_data$log_rt <- log(planet_encountered_data$rt)
planet_encountered_data$age_z <- scale_this(planet_encountered_data$age)
planet_encountered_data$within_block_trial_z <- scale_this(planet_encountered_data$within_block_trial)
planet_encountered_data$block_z <- scale_this(parse_number(planet_encountered_data$block))
planet_encountered_data$planet_lag_z <- scale_this(planet_encountered_data$planet_lag)
planet_encountered_data$transition_type <- factor(planet_encountered_data$transition_type)
planet_encountered_data$learning_correct_response <- factor(planet_encountered_data$learning_correct_response)
planet_encountered_data$planet <- factor(planet_encountered_data$planet)

#run RT analysis
rt_by_planet_encounter_transition_type <- mixed(log_rt ~ age_z * block_z * within_block_trial_z * planet_lag_z * transition_type + learning_correct_response + (planet_lag_z + within_block_trial_z + transition_type + learning_correct_response + block_z || subject_id) + (1| planet),
                               data = planet_encountered_data,
                               expand_re = T,
                               method = "S",
                               control = lmerControl(optCtrl=list(maxfun=1e6),
                                                     optimizer = "bobyqa"))

print_model_results(rt_by_planet_encounter_transition_type)

#note: is singular with interactions in RE, pruned

```

### Learning model with quadratic age
```{r learning rt model with quadratic age}

#transform variables
planet_encountered_data$age_squared_z <- scale_this(planet_encountered_data$age^2)

#run RT analysis
rt_by_planet_encounter_transition_type_age_squared <- mixed(log_rt ~ (age_z + age_squared_z) * block_z * within_block_trial_z * planet_lag_z * transition_type + learning_correct_response + (planet_lag_z + within_block_trial_z + transition_type + learning_correct_response + block_z || subject_id) + (1| planet),
                               data = planet_encountered_data,
                               expand_re = T,
                               method = "S",
                               control = lmerControl(optCtrl=list(maxfun=1e6),
                                                     optimizer = "bobyqa"))

print_model_results(rt_by_planet_encounter_transition_type_age_squared)

#compare models
anova(rt_by_planet_encounter_transition_type, rt_by_planet_encounter_transition_type_age_squared)

#quadratic model does not improve fit

```


#### Plot: Log response times across planet lags
```{r plot planet lag RT effects, fig.height = 5, fig.width = 7}

#compute subject means
sub_mean_rts <- planet_encountered_data %>%
    group_by(planet_lag, subject_id, transition_type) %>%
    summarize(mean_sub_rt = mean(log(rt)),
              sd_sub_rt = sd(log(rt)),
              N = n()) %>%
  filter(planet_lag < 100)

group_mean_rts <- sub_mean_rts %>%
    group_by(planet_lag, transition_type) %>%
    summarize(mean_rt = mean(mean_sub_rt),
              se_rt = sd(mean_sub_rt/sqrt(n())),
              mean_num_trials = mean(N)
              )

planet_recency_rt_plot <- ggplot(group_mean_rts, aes(x =  planet_lag, y = mean_rt, color = transition_type, fill = transition_type)) +
  geom_point() +
  geom_smooth(method = "lm") + 
  ylab("Mean Log Response Time (ms)") +
  xlab("Planet Lag") + 
  scale_color_manual(values = c(plot_colors[1], plot_colors[3]), name = "Transition Type") +
  scale_fill_manual(values = c(plot_colors[1], plot_colors[3]), name = "Transition Type") +
  graph_theme()
planet_recency_rt_plot
```


```{r plot transition type effects, fig.height = 5, fig.width = 5}

#compute subject means
sub_mean_rts <- planet_encountered_data %>%
    group_by(transition_type, within_block_trial, subject_id) %>%
    summarize(mean_sub_rt = mean(rt),
              sd_sub_rt = sd(rt),
              N = n()) 

group_mean_rts <- sub_mean_rts %>%
    group_by(transition_type, within_block_trial) %>%
    summarize(mean_rt = mean(mean_sub_rt),
              se_rt = sd(mean_sub_rt/sqrt(n()))
              )

trial_transition_rt_plot <- ggplot(group_mean_rts, aes(x =  within_block_trial, y = mean_rt, color = transition_type, fill = transition_type)) +
  geom_point(alpha = .2) +
  geom_smooth(method = "lm") + 
  ylab("Mean Response Time (ms)") +
  xlab("Trial") + 
  scale_color_manual(values = c(plot_colors[1], plot_colors[3]), name = "Transition Type") +
  scale_fill_manual(values = c(plot_colors[1], plot_colors[3]), name = "Transition Type") +
  graph_theme()
trial_transition_rt_plot
```

#### Plot: Response times across planet lags with transition type
```{r plot planet lag x transition type RT effects, fig.height = 5, fig.width = 4}

#rerun model to extract lmer object for plotting
rt_by_planet_encounter_transition_type.lmer <- mixed(log_rt ~ age_z * within_block_trial_z *block_z * planet_lag_z * transition_type + learning_correct_response + (planet_lag_z + within_block_trial_z + block_z + transition_type + learning_correct_response || subject_id),
                               data = planet_encountered_data,
                               expand_re = T,
                               method = "S",
                               control = lmerControl(optCtrl=list(maxfun=1e6),
                                                     optimizer = "bobyqa"),
                               return = "merMod")

plot_model(rt_by_planet_encounter_transition_type.lmer, 
           type = "pred", 
           line.size = 1.5,
           terms = c("planet_lag_z", "transition_type"),
           colors = c(plot_colors[1], plot_colors[3]),
           legend.title="Transition Type") +
  xlab("Planet Lag (z-scored)") +
  ylab("Predicted Log Response Time (ms)") +
  ggtitle("") + 
  graph_theme() +
  theme(legend.position = "top",
        legend.title = element_text(size = 12),
        legend.text = element_text(size = 11))
```

#### Plot: Response times across trials with transition type
```{r plot planet lag x trial RT effects, fig.height = 5, fig.width = 4}

plot_model(rt_by_planet_encounter_transition_type.lmer, 
           type = "pred", 
           line.size = 1.5,
           terms = c("within_block_trial_z", "transition_type"), 
           colors = c(plot_colors[1], plot_colors[3]),
           legend.title="Transition Type") +
  xlab("Within-Block Trial (z-scored)") +
  ylab("Predicted Log Response Time (ms)") +
  ggtitle("") + 
  graph_theme() +
  theme(legend.position = "top",
        legend.title = element_text(size = 12),
        legend.text = element_text(size = 11))
```

## Parsing

```{r parsing data processing}

#get parsing data
parsing_data <- data_all %>%
    filter(block %in% c("parseblock1", "parseblock2", "parseblock3", "parseblock4"))

#determine subjects included in learning
learning_subs <- filtered_learning_data %>%
  dplyr::select(subject_id) %>%
  unique()

#determine communities from learning
communities <- filtered_learning_data %>%
  dplyr::select(subject_id, planet, community) %>%
  unique()

#filter based on learning
parsing_data_filtered <- parsing_data %>%
  filter(subject_id %in% learning_subs$subject_id) %>%
  dplyr::select(subject_id, age, age_group, trial_index, block, rt, stimulus, parse) %>%
  mutate(planet = extract_numeric(stimulus)) 

#label communities
parsing_data_filtered <- full_join(parsing_data_filtered, communities, by = c('subject_id', 'planet'))

#determine transition type
parsing_data_filtered <- parsing_data_filtered %>%
    mutate(prev_community = lag(community),
           block_number = parse_number(as.character(block))) %>%
    ungroup() %>%
    mutate(transition_type = ifelse(prev_community == community, "within", "between"))

#determine trial number
parsing_data_filtered <- parsing_data_filtered %>%
  group_by(subject_id) %>%
  mutate(trial = rank(trial_index)) %>%
  ungroup()


#filter trials - exclude trials with parsing responses < 200 ms & first trial within each block
parsing_data_filtered$rt <- as.numeric(parsing_data_filtered$rt)
parsing_data_filtered <- parsing_data_filtered %>%
  filter(parse == FALSE | rt > 200) %>%
  filter(trial != 1) %>%
  filter(trial != 151) %>%
  filter(trial != 301) %>%
  filter(trial != 451)

#count trials since and to between
parsing_data_filtered <- parsing_data_filtered %>%
  group_by(subject_id, block_number) %>%
  mutate(trials_since_between = {
    counter <- 0
    sapply(transition_type, function(x) {
      if (x == "between") {
        counter <<- 0
      } else {
        counter <<- counter + 1
      }
      counter
    })
  })

parsing_data_filtered <- parsing_data_filtered %>%
  group_by(subject_id, block_number) %>%
  mutate(trials_to_between = {
    counter <- NA_integer_
    rev_result <- rev(sapply(rev(transition_type), function(x) {
      if (x == "between") {
        counter <<- 0
      } else if (!is.na(counter)) {
        counter <<- counter - 1
      }
      counter
    }))
    rev_result
  })
```

```{r exclude subjects from parsing}

#look at distribution of participant parsing responses
total_sub_parse <- parsing_data_filtered %>%
  group_by(subject_id) %>%
  summarize(total_parse = sum(parse),
            total_transition = sum(transition_type == "between", na.rm = T))

#plot
ggplot(total_sub_parse, aes(x = total_parse)) +
  geom_histogram(fill = plot_colors[3], color = "black", bins = 50) +
  xlab("Total Parsing Responses") +
  ylab("Number of Participants") +
  geom_vline(xintercept = 10, linetype = "dashed") +
  geom_vline(xintercept = 500, linetype = "dashed") +
  graph_theme()


#filter participants who parsed < 10 or > 500
parsing_data_filtered <- parsing_data_filtered %>%
  filter(subject_id %in% total_sub_parse$subject_id[total_sub_parse$total_parse > 10 & total_sub_parse$total_parse < 500]) %>%
  mutate(within_block_trial = trial - 150*(block_number - 1))

```


### Parsing responses by age, trial, transition type
```{r parsing model}

#select variables
parsing_model_data <- parsing_data_filtered %>%
  dplyr::select(subject_id, parse, rt, transition_type, within_block_trial, trial, age, age_group, planet, block_number) 

#scale
parsing_model_data$trial_z <- scale_this(parsing_model_data$trial)
parsing_model_data$within_block_trial_z <- scale_this(parsing_model_data$within_block_trial)
parsing_model_data$age_z <- scale_this(as.numeric(parsing_model_data$age))
parsing_model_data$subject_id <- factor(parsing_model_data$subject_id)
parsing_model_data$planet <- factor(parsing_model_data$planet)
parsing_model_data$block_z <- scale_this(parsing_model_data$block_number)


#run parsing analysis
parsing_by_transition_type <- mixed(parse ~ age_z * block_z * within_block_trial_z * transition_type  + (block_z + within_block_trial_z + transition_type|| subject_id) + (1|planet),
                                    family = "binomial",
                                    data = parsing_model_data,
                                    control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=1e6)),
                                    expand_re = T,
                                    method = "LRT")

print_log_model_results(parsing_by_transition_type)

#singular fit with interactions in RE

```

```{r parsing model quadratic age}

#compute qudartic age
parsing_model_data$age_squared_z <- scale_this(as.numeric(parsing_model_data$age^2))

#run parsing analysis
parsing_by_transition_type_quadratic_age <- mixed(parse ~ (age_z + age_squared_z) * block_z * within_block_trial_z * transition_type  + (block_z + within_block_trial_z + transition_type|| subject_id) + (1|planet),
                                    family = "binomial",
                                    data = parsing_model_data,
                                    control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=1e6)),
                                    expand_re = T,
                                    method = "LRT")

print_log_model_results(parsing_by_transition_type_quadratic_age)

#compare models - quadratic model does not fit better
anova(parsing_by_transition_type, parsing_by_transition_type_quadratic_age)

#quadratic age model does not fit better

```


#### Plot: Parsing responses by age group and transition type
```{r plot parsing, fig.height = 5, fig.width = 6}

parsing_sub_means <- parsing_model_data %>%
  group_by(subject_id, age_group, transition_type) %>%
  summarize(mean_sub_parse = mean(parse, na.rm = T))

parsing_group_means <- parsing_sub_means %>%
  group_by(age_group, transition_type) %>%
  summarize(mean_parse = mean(mean_sub_parse),
            se_parse = sd(mean_sub_parse)/ sqrt(n()))

#plot
parsing_plot <- ggplot(parsing_sub_means, aes(x = transition_type, y = mean_sub_parse, color = transition_type)) +
    facet_wrap(~age_group) +
    geom_point() +
    geom_line(aes(group = subject_id), color = "lightgrey") +
    geom_line(data = parsing_group_means, aes(x = transition_type, y = mean_parse, group = age_group), color = "black") +
    geom_point(data = parsing_group_means, aes(x = transition_type, y = mean_parse), size = 3, shape = 23, fill = "black") +
    geom_errorbar(data = parsing_group_means, aes(x = transition_type, y = mean_parse, ymin = mean_parse - se_parse, ymax = mean_parse + se_parse), width =.1, color = "black") +
    xlab("Transition Type") +
    ylab("Proportion of Parsing Responses") +
    scale_color_manual(values = c(plot_colors[1], plot_colors[3]), name = "Transition Type") +
    graph_theme() +
    theme(legend.position = "none") 
 # ggtitle("Parsing")
parsing_plot
```

### Parsing responses by age, trial, transition type, planet lag

```{r parsing based on planet recency data processing}

parsing_planet_recency_data <- parsing_data_filtered %>%
  mutate(within_block_trial = trial - (150 * (block_number-1))) %>%
  group_by(subject_id) %>%
  group_by(planet) %>%
  mutate(planet_lag = within_block_trial - lag(within_block_trial, default = first(within_block_trial)) - 1) %>%
  ungroup() %>%
  dplyr::select(subject_id, parse, rt, transition_type, within_block_trial, trial, age, age_group, planet, planet_lag, block_number) %>%
  #drop_na() %>%
  filter(planet_lag > 0)

```

```{r parsing model with both recency and transition type}

parsing_planet_recency_data$age_z <- scale_this(parsing_planet_recency_data$age)
parsing_planet_recency_data$within_block_trial_z <- scale_this(parsing_planet_recency_data$within_block_trial)
parsing_planet_recency_data$planet_lag_z <- scale_this(parsing_planet_recency_data$planet_lag)
parsing_planet_recency_data$parse <- factor(parsing_planet_recency_data$parse)
parsing_planet_recency_data$block_z <- scale_this(parsing_planet_recency_data$block_number)

#run parsing analysis
parsing_by_planet_encounter_transition_type <- mixed(parse ~ age_z * block_z * within_block_trial_z * planet_lag_z * transition_type + (block_z + planet_lag_z + transition_type || subject_id) + (1|planet),
                               data = parsing_planet_recency_data,
                               family = "binomial",
                               control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=1e6)),
                               expand_re = T,
                               method = "LRT")

print_log_model_results(parsing_by_planet_encounter_transition_type)

# effects of:
# age
# trials since planet 
# transition type
# trial x trials since planet
# age x transition type
# trial x transition type

```


```{r parsing model with both recency and transition type quadratic age, eval = F}
parsing_planet_recency_data$age_squared_z <- scale_this(parsing_planet_recency_data$age^2)

#run parsing analysis
parsing_by_planet_encounter_transition_type_age_squared <- mixed(parse ~ (age_z + age_squared_z) * block_z * within_block_trial_z * planet_lag_z * transition_type + (planet_lag_z + transition_type || subject_id) + (1|planet),
                               data = parsing_planet_recency_data,
                               family = "binomial",
                               control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=1e6)),
                               expand_re = T,
                               method = "LRT")

print_log_model_results(parsing_by_planet_encounter_transition_type_age_squared)

#compare models
anova(parsing_by_planet_encounter_transition_type, parsing_by_planet_encounter_transition_type_age_squared)

```

### Children-only parsing responses by age, trial, transition type
```{r children-only parsing model}

#filter to only include children
parsing_child_data <- parsing_planet_recency_data %>%
  filter(age < 13)

#scale
parsing_child_data$within_block_trial_z <- scale_this(parsing_child_data$within_block_trial)
parsing_child_data$block_z <- scale_this(parsing_child_data$block_number)
parsing_child_data$subject_id <- factor(parsing_child_data$subject_id)
parsing_child_data$planet <- factor(parsing_child_data$planet)
parsing_child_data$planet_lag_z <- scale_this(parsing_child_data$planet_lag)


#run parsing analysis
parsing_by_transition_type_children <- mixed(parse ~ block_z * within_block_trial_z * planet_lag_z * transition_type  + (within_block_trial_z + planet_lag_z + transition_type|| subject_id) + (1|planet),
                                    family = "binomial",
                                    data = parsing_child_data,
                                    control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=1e6)),
                                    expand_re = T,
                                    method = "LRT")

print_log_model_results(parsing_by_transition_type_children)

```



#### Plot: Parsing responses by age, transition type, planet lag, trial
```{r plot parsing planet lag, fig.height = 5, fig.width = 6}

#re-run model and extract glmer object
parsing_by_planet_encounter_transition_type.glmer <- mixed(parse ~ age_z *block_z * within_block_trial_z * planet_lag_z * transition_type + (planet_lag_z + transition_type || subject_id) + (1|planet),
                               data = parsing_planet_recency_data,
                               family = "binomial",
                               control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=1e6)),
                               expand_re = T,
                               method = "LRT",
                               return = "merMod")



plot_model(parsing_by_planet_encounter_transition_type.glmer, 
           type = "pred", 
           line.size = 1.5,
           terms = c("within_block_trial_z", "transition_type", "age_z"), 
           colors = c(plot_colors[1], plot_colors[3]),
           legend.title="Transition Type") +
  xlab("Trial (z-scored)") +
  ylab("Predicted Parsing Probability") +
  ggtitle("") + 
  graph_theme() +
  theme(legend.position = "top",
        legend.title = element_text(size = 12),
        legend.text = element_text(size = 11))

plot_model(parsing_by_planet_encounter_transition_type.glmer, 
           type = "pred", 
           line.size = 1.5,
           terms = c("planet_lag_z", "within_block_trial_z", "age_z"), 
           colors = c(plot_colors[1], plot_colors[2], plot_colors[3]),
           legend.title="Trial (Z)") +
  xlab("Planet Lag (z-scored)") +
  ylab("Predicted Parsing Probability") +
  ggtitle("") + 
  graph_theme() +
  theme(legend.position = "top",
        legend.title = element_text(size = 12),
        legend.text = element_text(size = 11))

```



### Plot: Probability of parsing as a functon of trials around transition types
```{r plot parsing by trials from between transition, fig.height = 5, fig.width = 4}

parsing_after_transitions_sub <- parsing_data_filtered %>%
  group_by(subject_id, trials_since_between) %>%
  summarize(mean_sub_parse = mean(parse, na.rm = TRUE)) %>%
   filter(trials_since_between < 5)

parsing_after_transitions <- parsing_after_transitions_sub %>%
  group_by(trials_since_between) %>%
  summarize(mean_parse = mean(mean_sub_parse, na.rm = TRUE),
            se_parse = sd(mean_sub_parse, na.rm = TRUE)/sqrt(n())) %>%
  filter(trials_since_between < 5)

#make bar plot
parsing_after_transition <- ggplot(parsing_after_transitions, aes(x = factor(trials_since_between), y = mean_parse)) +
  geom_bar(stat = "identity", position = "dodge", fill = plot_colors[1], color = "black") +
  geom_errorbar(aes(ymin = mean_parse - se_parse, ymax = mean_parse + se_parse), width = 0.1, color = "black", position = position_dodge(width = .9)) +
  ylab("Mean Proportion of Parsing Responses") +
  xlab("Trials Since Last Between Transition") + 
  graph_theme()
parsing_after_transition

```

```{r plot parsing by trials before between transition, fig.height = 5, fig.width = 4}

parsing_before_transitions_sub <- parsing_data_filtered %>%
  group_by(subject_id, trials_to_between) %>%
  summarize(mean_sub_parse = mean(parse, na.rm = TRUE)) %>%
   filter(trials_to_between > -5)

parsing_before_transitions <- parsing_before_transitions_sub %>%
  group_by(trials_to_between) %>%
  summarize(mean_parse = mean(mean_sub_parse, na.rm = TRUE),
            se_parse = sd(mean_sub_parse, na.rm = TRUE)/sqrt(n())) %>%
  filter(trials_to_between > -5)

#make bar plot
parsing_before_transition <- ggplot(parsing_before_transitions, aes(x = factor(trials_to_between), y = mean_parse)) +
  geom_bar(stat = "identity", position = "dodge", fill = plot_colors[2], color = "black") +
  geom_errorbar(aes(ymin = mean_parse - se_parse, ymax = mean_parse + se_parse), width = 0.1, color = "black", position = position_dodge(width = .9)) +
  ylab("Mean Proportion of Parsing Responses") +
  xlab("Trials Leading To Between Transition") + 
  graph_theme()
parsing_before_transition

```


# Graph reconstruction
```{r read in reconstruction data}

graph_data <- list.files(path = data_dir,  
                       pattern = "graph_reconstruction*", 
                       full.names = TRUE) %>% 
  lapply(read_csv) %>%
  bind_rows 

#add communities
graph_data <- inner_join(graph_data, communities, by = c('subject_id', 'planet')) %>%
  mutate(community_num = parse_number(community))

#only include subjects included in learning
graph_data <- graph_data %>%
  filter(subject_id %in% learning_subs$subject_id)

```

## Filter out subjects who didn't move the planets
```{r filter graph reconstruction data}

#determine subjects who didn't move any planets
graph_movement_summary <- graph_data %>%
  group_by(subject_id, planet) %>%
  summarize(total_movement = sum(sqrt((x - x_init)^2 + (y - y_init)^2))) %>%
  group_by(subject_id) %>%
  summarize(no_movement_planets = sum(total_movement == 0))

#determine how many planets each participant moved
graph_movement_summary_plot <- ggplot(graph_movement_summary, aes(x = no_movement_planets)) +
  geom_histogram(fill = plot_colors[3], color = "black", bins = 16) +
  xlab("Number of Planets Not Moved") +
  ylab("Number of Participants") +
  graph_theme()
graph_movement_summary_plot

#overall stats
planet_movement_summary <- graph_movement_summary %>%
  summarize(mean_no_movement = mean(no_movement_planets),
            mean_n_movement = mean(15 - no_movement_planets),
            sd_no_movement = sd(no_movement_planets),
            sd_n_movement = sd(15 - no_movement_planets),
            max_no_movement = max(no_movement_planets),
            min_no_movement = min(no_movement_planets))
planet_movement_summary
            
```

## Compute empirical distance matrices
```{r empirical graph reconstruction matrices}

#for each participant, construct matrix of pairwise distances between planets
graph_reconstruction_matrix <- function(df) {
  subjects <- unique(df$subject_id)
  results <- list()
  
  for (subject in subjects) {
    subject_df <- df[df$subject_id == subject, ]
    distance_matrix <- proxy::dist(subject_df[, c("x", "y")], method = "euclidean")
    results[[as.character(subject)]] <- as.matrix(distance_matrix)
  }
  
  #normalize all distances by dividing by max
  results <- lapply(results, function(mat) {
    max_val <- max(mat, na.rm = TRUE)
    mat /max_val
  })
  
  return(results)
}

graph_reconstruction_matrices <- graph_reconstruction_matrix(graph_data)

```

## Compute ground-truth geodesic distances
```{r geodesic distance matrix}

#  construct geodesic distance matrix based on node
edges <- c(1, 2,
           1, 3,
           1, 4,
           1, 15,
           2, 3,
           2, 4,
           2, 5,
           3, 4, 
           3, 5,
           4, 5,
           5, 6,
           6, 7,
           6, 8, 
           6, 9,
           7, 8,
           7, 9,
           7, 10,
           8, 9,
           8, 10,
           9, 10,
           10, 11,
           11, 12,
           11, 13,
           11, 14,
           12, 13, 
           12, 14, 
           12, 15,
           13, 14,
           13, 15,
           14, 15)

g <- graph(edges, directed = FALSE)
dist_mat <- distances(g)
rownames(dist_mat) <- colnames(dist_mat) <- as.character(1:15)


# Relabel for each subject based on their node → stim_id mapping
subject_dist_mats <- list()

for (sub in unique(all_planets$subject_id)) {
  
  sub_planets <- all_planets %>% filter(subject_id == sub)
  
  # Map node IDs (1–15) → stim_id for this subject
  node_to_stim <- setNames(sub_planets$stim_id, as.character(sub_planets$node))
  
  # Make a copy and relabel
  dist_mat_sub <- dist_mat
  
  # Relabel with stim_id
  rownames(dist_mat_sub) <- node_to_stim[rownames(dist_mat_sub)]
  colnames(dist_mat_sub) <- node_to_stim[colnames(dist_mat_sub)]

  # Assuming row and col names are character versions of numbers, convert to numeric
  stim_ids <- as.numeric(rownames(dist_mat_sub))

  # Sort stim_ids numerically
  stim_order <- sort(stim_ids)

  # Convert back to character to use as row/col names
  stim_order_chr <- as.character(stim_order)

# Reorder distance matrix
  dist_mat_sub <- dist_mat_sub[stim_order_chr, stim_order_chr]
  
  subject_dist_mats[[as.character(sub)]] <- dist_mat_sub
}

```



## RSA with geodesic matrix

```{r representational similarity analyses}

# Get subject IDs present in both
common_subjects <- intersect(names(graph_reconstruction_matrices), names(subject_dist_mats))

# Filter both lists to shared subjects, preserving order
graph_reconstruction_filtered <- graph_reconstruction_matrices[common_subjects]
subject_dist_mats_filtered <- subject_dist_mats[common_subjects]

# Function to compute Pearson correlation between two distance matrices
compute_similarity <- function(mat1, mat2) {
  vec1 <- as.vector(mat1[lower.tri(mat1)])
  vec2 <- as.vector(mat2[lower.tri(mat2)])
  cor(vec1, vec2, method = "pearson")
}

# Compute similarity for each subject
similarities <- mapply(compute_similarity, graph_reconstruction_filtered, subject_dist_mats_filtered)
names(similarities) <- names(graph_reconstruction_filtered)

similarity_df <- as.data.frame(similarities) %>%
  rownames_to_column(var = "subject_id") %>%
  rename(rsa = similarities) %>%
  mutate(subject_id = as.numeric(subject_id)) %>%
  inner_join(age_data, by = "subject_id") %>%
  mutate(age_group = case_when(age < 13 ~ "Children",
                                age > 12.99 & age < 18 ~ "Adolescents",
                                age > 17.99 ~ "Adults"))

similarity_df$age_group <- factor(similarity_df$age_group, levels = c("Children", "Adolescents", "Adults"))
```


```{r plots of best and worst graph reconstruction subject, fig.width = 6, fig.height = 5}

similarity_df <- similarity_df %>% 
  arrange(rsa)

#best subject
# select subject
sub_id <- similarity_df$subject_id[nrow(similarity_df)]

#get subject communities
sub_communities <- learning_data %>%
  filter(subject_id == sub_id) %>%
  select(planet, community) %>%
  distinct()

#get sub interior vs. exterior
sub_planet_type <- all_planets %>%
  filter(subject_id == sub_id) %>%
  select(planet = stim_id, planet_type)

#combine
sub_planet_info <- full_join(sub_communities, sub_planet_type, by = "planet") %>%
  mutate(planet = as.character(planet))


#get x/y coordinates
df <- graph_data %>% 
  filter(subject_id == sub_id) %>%
  select(planet, x, y) %>%
  mutate(planet = as.character(planet))

# Add community and planet type information
df <- df %>%
  left_join(sub_planet_info, by = "planet") %>%
  mutate(planet_type = factor(planet_type, levels = c("interior", "exterior")),
         community_num = parse_number(community))

ggplot(df, aes(x = x, y = y, label = planet, color = factor(community_num), alpha = planet_type)) +
  geom_point(size = 3) +
  ggtitle("Graph Reconstruction: Best Participant") +
  scale_color_manual(values = c(plot_colors[1], plot_colors[2], plot_colors[3]), name = "Community") +
  scale_alpha_manual(values = c(.5, 1), name = "Planet Type", labels = c("Interior", "Exterior")) +
  graph_theme() +
  theme(title = element_text(size = 14),
        legend.text = element_text(size = 12)) + 
  coord_equal()


#worst subject
# select subject
sub_id <- similarity_df$subject_id[1]

#get subject communities
sub_communities <- learning_data %>%
  filter(subject_id == sub_id) %>%
  select(planet, community) %>%
  distinct()

#get sub interior vs. exterior
sub_planet_type <- all_planets %>%
  filter(subject_id == sub_id) %>%
  select(planet = stim_id, planet_type)

#combine
sub_planet_info <- full_join(sub_communities, sub_planet_type, by = "planet") %>%
  mutate(planet = as.character(planet))


#get x/y coordinates
df <- graph_data %>% 
  filter(subject_id == sub_id) %>%
  select(planet, x, y) %>%
  mutate(planet = as.character(planet))

# Add community and planet type information
df <- df %>%
  left_join(sub_planet_info, by = "planet") %>%
    mutate(planet_type = factor(planet_type, levels = c("interior", "exterior")),
         community_num = parse_number(community))

ggplot(df, aes(x = x, y = y, label = planet, color = factor(community_num), alpha = planet_type)) +
  geom_point(size = 3) +
  ggtitle("Graph Reconstruction: Worst Participant") +
  scale_color_manual(values = c(plot_colors[1], plot_colors[2], plot_colors[3]), name = "Community") +
  scale_alpha_manual(values = c(.3, 1), name = "Planet Type", labels = c("Interior", "Exterior")) +
  graph_theme() +
  theme(title = element_text(size = 14),
        legend.text = element_text(size = 12)) + 
  coord_equal()



```

## Is RSA above 0?
```{r is RSA above 0}

rsa_t.test <- t.test(similarity_df$rsa, mu = 0)

rsa_t.test

```

## RSA scores by age
```{r analyze similarity by age}

#scale age
similarity_df$age_z <- scale_this(similarity_df$age)

#run model
similarity_model <- lm(rsa ~ age_z, data = similarity_df)
anova(similarity_model)
```

```{r analyze similarity by quadratic age}

#scale age
similarity_df$age_squared_z <- scale_this(similarity_df$age^2)

#run model
similarity_model_age_squared <- lm(rsa ~ (age_z + age_squared_z), data = similarity_df)
summary(similarity_model_age_squared)

#compare models
anova(similarity_model, similarity_model_age_squared)
```


```{r plot RSA by age}

rsa_age_plot <- ggplot(similarity_df, aes(x = age, y = rsa)) +
    geom_point(color = plot_colors[5]) +
    geom_smooth(method = "lm", color = "black") +
  xlab("Age") + 
  ylab("Representational Similarity (RSA)") +
  graph_theme()
rsa_age_plot
```


# Model-derived parameter analyses

```{r read in julia modeling results}

#read in modeling results
model_results <- read_csv("data/processed/model_individ_params.csv") %>%
  rename(β_C = β_anticipation,
        β_R = β_zero_order)

#combine with age
model_results <- inner_join(model_results, age_data, by = c("subject_id"))
```

## Relations between parameters and age
### Plot: Relation between β_C and age

```{r beta c age plot, fig.height = 5, fig.width = 5}

#plot correlation between age and beta_anticipation
ggplot(model_results, aes(x = age, y = β_C)) +
  geom_point(color = plot_colors[5]) +
  geom_smooth(method = "lm", color = 'black') +
  xlab("Age") +
  ylab(expression(beta[C])) +
  graph_theme()
```

### Plot: Relation between β_R and age

```{r beta r age plot, fig.height = 5, fig.width = 5}

ggplot(model_results, aes(x = age, y = β_R)) +
  geom_point(color = plot_colors[5]) +
  geom_smooth(method = "lm", color = "black") +
  xlab("Age") +
  ylab(expression(beta[R])) +
  graph_theme()
```


### Plot: Relation between γ and age

```{r gamma age plot, fig.height = 5, fig.width = 5}

ggplot(model_results, aes(x = age, y = γ)) +
  geom_point(color = plot_colors[5]) +
  geom_smooth(method = "lm", color = "black") +
  xlab("Age") +
  ylab(expression(gamma)) +
  graph_theme()


```


### Plot: Relation between β_C and β_R

```{r beta c beta r plot, fig.height = 5, fig.width = 5}

#plot correlation between beta_R and beta_C
ggplot(model_results, aes(x = β_R, y = β_C)) +
  geom_point(color = plot_colors[5]) +
  geom_smooth(method = "lm", color = 'black') +
  xlab(expression(beta[R])) +
  ylab(expression(beta[C])) +
  graph_theme()
```

## Relations between parameters and explicit knowledge

### Relation between β_C and graph reconstruction
```{r model relation between beta_c and rsa}

#join with dist prop
data <- inner_join(model_results, similarity_df, by = c("subject_id", "age"))

#z-score variables
data$age_z <- scale_this(data$age)
data$beta_c_z <- scale_this(data$β_C)

#run model
beta_c_rsa_model <- lm(rsa ~ beta_c_z, data = data)
summary(beta_c_rsa_model)

# no significant effects
# also no significant effects wtih age in model
```


### Relation between γ and graph reconstruction
```{r model relation between gamma and rsa}

#z-score variables
data$gamma_z <- scale_this(data$γ)

#run model
gamma_rsa_model <- lm(rsa ~ gamma_z, data = data)
summary(gamma_rsa_model)

#no effect
#also no effect with age
```


### Relation between β_R and rsa
```{r model relation between betaR and rsa}

#z-score variables
data$beta_r_z <- scale_this(data$β_R)

#run model
beta_r_rsa_model <- lm(rsa ~  beta_r_z, data = data)
summary(beta_r_rsa_model)

# no relation
```




### Relation between β_C and parsing
```{r parsing model param data processing}

#select model results
model_results_select <- model_results %>%
  dplyr::select(subject_id, β_C, β_R, γ)

#join model results with parsing model data
model_results_select$subject_id <- as.factor(model_results_select$subject_id)
parsing_planet_recency_data$subject_id <- as.factor(parsing_planet_recency_data$subject_id)
parsing_parameter_mixed_model_data <- inner_join(model_results_select, parsing_planet_recency_data, by = c("subject_id"))

```

```{r parsing and beta c}

#z-score variables
parsing_parameter_mixed_model_data$age_z <- scale_this(parsing_parameter_mixed_model_data$age)
parsing_parameter_mixed_model_data$beta_c_z <- scale_this(parsing_parameter_mixed_model_data$β_C)
parsing_parameter_mixed_model_data$within_block_trial_z <- scale_this(parsing_parameter_mixed_model_data$within_block_trial)
parsing_parameter_mixed_model_data$transition_type <- factor(parsing_parameter_mixed_model_data$transition_type)
parsing_parameter_mixed_model_data$planet_lag_z <- scale_this(parsing_parameter_mixed_model_data$planet_lag)
parsing_parameter_mixed_model_data$block_z <- scale_this(parsing_parameter_mixed_model_data$block_number)


#run parsing analysis - do age x transition type effects go away when you account for beta_c?
parsing_beta_c <- mixed(parse ~ (age_z + beta_c_z) * (transition_type + planet_lag_z + within_block_trial_z + block_z) + (transition_type + planet_lag_z + within_block_trial_z + block_z || subject_id),
                         data = parsing_parameter_mixed_model_data,
                         family = "binomial",
                         control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=1e6)),
                         expand_re = T,
                         method = "LRT")

parsing_beta_c
```


### Relation between β_R and parsing 
```{r parsing and beta r}

#z-score variables
parsing_parameter_mixed_model_data$beta_r_z <- scale_this(parsing_parameter_mixed_model_data$β_R)


#run parsing analysis - do age x transition type effects go away when you account for beta_c?
parsing_beta_r <- mixed(parse ~ (age_z + beta_r_z) * (transition_type + planet_lag_z + within_block_trial_z + block_z) + (transition_type + planet_lag_z + within_block_trial_z + block_z || subject_id),
                         data = parsing_parameter_mixed_model_data,
                         family = "binomial",
                         control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=1e6)),
                         expand_re = T,
                         method = "LRT")

parsing_beta_r

```

